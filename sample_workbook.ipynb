{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/image.jpg\" alt=\"Tableau Meta\" width=\"300\" height=\"300\" style=\"float:left; margin-right: 40px; margin-bottom: 20px;\" />\n",
    "\n",
    "# Banner to Smartsheet Data Migration  \n",
    "### Migrating Data from Banner to Smartsheet using SQL and Python  \n",
    "\n",
    "<div style=\"clear: both;\"></div>  \n",
    "\n",
    "## Disclaimer  \n",
    "This content is designed for **beginner-level** team members, so concepts and terminology are explained in a simplified manner.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Purpose & Overview**  \n",
    "This notebook provides a **baseline of fundamental tools and methods** for **extracting, transforming, and loading (ETL) data** between different systems. The goal is to introduce **repeatable, adaptable workflows** that can be **repurposed** for various data migration scenarios, including:  \n",
    "\n",
    "- Moving structured data from **Banner (or other databases) to Smartsheet**  \n",
    "- Automating **data extraction, transformation, and validation** using SQL and Python  \n",
    "- Scheduling **automated updates** to keep destination systems in sync with source data  \n",
    "\n",
    "By learning these foundational concepts and workflows, you will be able to **extend these techniques** to support **a wide range of ETL use cases** beyond this specific migration process.  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Table of Contents**  \n",
    "### **Prerequisites**  \n",
    "Before proceeding, ensure you meet the following requirements:  \n",
    "\n",
    "- You have access to a [SQL Server database](https://ts.vcu.edu/about-us/computer-center/database-administration/sql-server/) with **Admin rights** or know the Admin who can make updates.  \n",
    "- A database is set up to store ODS data (a new one can be created if you have Admin privileges).  \n",
    "- You have **ownership or admin rights** to the target database.  \n",
    "- **Microsoft SQL Server Management Studio (SSMS)** is installed on your local machine, and you have VPN access.  \n",
    "- You have a development environment (IDE) set up for **Python 3.9** and Jupyter Notebooks (`pip install -r requirements.txt`).  \n",
    "- You have an active **Smartsheet license**.  \n",
    "- **Security & Compliance:** You have **explicit approval** from **InfoSec and the Banner team** to use your Banner data in Smartsheet.  \n",
    "- **Best Practice:** In production environments, use a **service account** for production ownership roles.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: Overview**  \n",
    "This step covers the fundamental setup and concepts required before migrating data.  \n",
    "\n",
    "### **1.1 Review IDE Setup**  \n",
    "- **Virtual environments (`venv`)**  \n",
    "- **Notebook operations**  \n",
    "- **`requirements.txt` usage**  \n",
    "- **Folder and file structure**  \n",
    "\n",
    "### **1.2 Review SQL Management Studio (SSMS)**  \n",
    "- **Tables and views**  \n",
    "- **SQL operations**  \n",
    "\n",
    "### **1.3 Smartsheet Setup**  \n",
    "- **API Key**  \n",
    "- **Sheet ID**  \n",
    "- **Field requirements**  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2: Walkthrough**  \n",
    "A step-by-step guide to migrating data.  \n",
    "\n",
    "### **2.1 Install Dependencies**  \n",
    "- Install the required libraries:  \n",
    "  ```bash\n",
    "  pip install -r requirements.txt\n",
    "\n",
    "### **2.2 Import Required Modules**  \n",
    "- Import necessary Python libraries for database access and API interaction.  \n",
    "\n",
    "### **2.3 Set Up Smartsheet**  \n",
    "- Obtain API token and Sheet ID.\n",
    "\n",
    "### **2.4 Configure Variables**  \n",
    "- Update credentials and API keys in your script.\n",
    "\n",
    "### **2.5 Initialize Objects**  \n",
    "- Create database connections and Smartsheet API objects.\n",
    "\n",
    "### **2.6 Load Test Data into SQL & Create a SQL View**  \n",
    "- Import sample data into SQL Server.\n",
    "- Create a SQL view for extracting relevant data.\n",
    "\n",
    "### **2.7 Load SQL Data into Smartsheet & Test API Methods**  \n",
    "- Extract data from SQL Server and upload it to Smartsheet.\n",
    "\n",
    "### **2.8 Copy ODS Tables to Your Database**  \n",
    "- Perform data transfer from the ODS system to your target database.\n",
    "\n",
    "### **2.9 Create a Stored Procedure to Refresh ODS Data**  \n",
    "- Automate data updates using SQL stored procedures.\n",
    "\n",
    "### **2.10 Schedule an Automated Data Refresh**  \n",
    "- Configure a SQL Agent Job to refresh ODS data on a schedule.\n",
    "\n",
    "### **2.11 Create an Optional View from ODS Data Tables**  \n",
    "- Build a SQL view to facilitate easier data access and analysis.\n",
    "\n",
    "### **2.12 Review & Validate Data**  \n",
    "- Ensure data is correctly migrated and matches expectations.\n",
    "\n",
    "\n",
    "\n",
    "## **Step 3: Tips & Tricks** \n",
    "\n",
    "### **3.1 Can We Load Data Directly from the ODS Linked Server?**  \n",
    "- ✅ Yes, but it depends on access permissions and performance considerations.\n",
    "\n",
    "### **3.2 Other API Data Considerations**  \n",
    "- Handling different data structures via API calls.\n",
    "\n",
    "### **3.3 Can Python Jobs be Automated/Scheduled?**  \n",
    "- ✅ Yes, but it depends machine access and error checking.\n",
    "\n",
    "---\n",
    "\n",
    "## **Additional Resources**  \n",
    "\n",
    "### **Smartsheet API Documentation**  \n",
    "For more details on Smartsheet API methods, refer to the **[Smartsheet API Reference](https://smartsheet.redoc.ly/)**.  \n",
    "\n",
    "### **Download SQL Server Management Studio (SSMS)**  \n",
    "[Download Here](https://learn.microsoft.com/en-us/sql/ssms/download-sql-server-management-studio-ssms?view=sql-server-ver16)  \n",
    "\n",
    "---\n",
    "\n",
    "## **IDE Recommendations**  \n",
    "Choosing an IDE depends on your experience and long-term needs:  \n",
    "\n",
    "### **Beginner-Friendly (Quick Setup, but Limited Long-Term Scalability)**  \n",
    "- **[Anaconda](https://www.anaconda.com/download)** – Easier setup but may become restrictive for larger projects.  \n",
    "\n",
    "### **More Robust & Flexible (Requires Manual Setup, but Scalable for Larger Projects)**  \n",
    "- **[Visual Studio Code](https://code.visualstudio.com/download)** – A lightweight but powerful IDE for Python development.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Step 1: Overview**  \n",
    "This step covers the fundamental setup and concepts required before migrating data.  \n",
    "\n",
    "### **1.1 Review IDE Setup**  \n",
    "- **Virtual environments (`venv`)**  \n",
    "- **Notebook operations**  \n",
    "- **`requirements.txt` usage**  \n",
    "- **Folder and file structure**  \n",
    "\n",
    "### **1.2 Review SQL Management Studio (SSMS)**  \n",
    "- **Tables and views**  \n",
    "- **SQL operations**  \n",
    "\n",
    "### **1.3 Smartsheet Setup**  \n",
    "- **API Key**  \n",
    "- **Sheet ID**  \n",
    "- **Field requirements**  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2: Walkthrough**  \n",
    "A step-by-step guide to migrating data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: The following cell only needs to be ran during the initial implementation\n",
    "### **2.1 Install Dependencies**  \n",
    "- Install the required libraries:  \n",
    "  ```bash\n",
    "  pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt # comment out when done loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Import Required Modules**  \n",
    "- Import necessary Python libraries for database access and API interaction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following cell to import the required packages each time you start a new session \n",
    "import pyodbc\n",
    "import concurrent.futures\n",
    "import sqlalchemy\n",
    "from sqlalchemy import Column, BigInteger, DateTime, Integer, String, Enum as EnumColumn, Float, create_engine, text, Table, inspect, MetaData, types \n",
    "from sqlalchemy.orm import column_property, sessionmaker\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from functions.utliz_sql import *\n",
    "from functions.smartsh import _SysSmartsheetServices\n",
    "import pandas as pd\n",
    "import smartsheet\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3 Set Up Smartsheet**  \n",
    "- Obtain API token and Sheet ID.\n",
    "    - Create a Smartsheet workspace then create a \"Grid\" file\n",
    "    - It's assumed you may not have data in your SQL database so we'll use a dataset about movies for testing  \n",
    "        - Use movie_date_field_names.csv found in the sample_data folder and import this file to quickly build the field titles. Note: make sure to save the file\n",
    "    - Get your Sheet ID by going to File->Properties and copy the value found in the field <b>Sheet ID</b> and store for later use\n",
    "    - Create your Smartsheet API token by following these [API Token Steps](https://help.smartsheet.com/articles/2482389-generate-API-key) and store somewhere safe for later use\n",
    "    - Add your Sheet ID and API token to the following cell in their respective areas in the following cell within the quoation marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.4 Configure Variables**  \n",
    "- Update credentials and API keys in your script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"REPLACE_TEXT_HERE\"\n",
    "database = 'REPLACE_TEXT_HERE'\n",
    "username = \"REPLACE_TEXT_HERE\"\n",
    "password = \"REPLACE_TEXT_HERE\" \n",
    "smartsheet_api_key = 'REPLACE_TEXT_HERE'\n",
    "sheet_id = 'REPLACE_TEXT_HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.5 Initialize Objects**  \n",
    "- Create database connections and Smartsheet API objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the smartsheet and sql objects\n",
    "smartsheet_init = _SysSmartsheetServices(smartsheet_api_key)\n",
    "_sys_info_services = SysInfoServices(server, database, username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.6 Load Test Data into SQL & Create a SQL View**  \n",
    "- Import sample data into SQL Server.\n",
    "- Create a SQL view for extracting relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because it's assumed you may not have Banner data in your SQL database we'll load a testing dataset about movies into your database\n",
    "# using two tables that we'll combine into one view prior to loading into Smartsheet. Logic can be updated to use your target Banner data\n",
    "\n",
    "# load the 2 source csv filed into 2 dataframes \n",
    "table1_df = pd.read_csv('sample_data/movie_data_t1.csv') \n",
    "table2_df = pd.read_csv('sample_data/movie_data_t2.csv') \n",
    "\n",
    "table1_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create/update SQL tables using the dataframes in your target database\n",
    "_sys_info_services.update_sql_table_with_dataframe(table1_df, 'test_movie_data_t1')\n",
    "_sys_info_services.update_sql_table_with_dataframe(table2_df, 'test_movie_data_t2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create view by copy/pasting the following into the SQL query via the image below\n",
    "   \n",
    "        -- Use CREATE for inital build and ALTER when updating\n",
    "        --ALTER VIEW vw_test_movie_demo AS -- uncomment this to update while commenting out the CREATE line\n",
    "            CREATE VIEW vw_test_movie_demo AS\n",
    "            SELECT\n",
    "                t1.[show_id],\n",
    "                t1.[title], \n",
    "                t1.[director], \n",
    "                t1.[cast], \n",
    "                t1.[country], \n",
    "                t1.[date_added],\n",
    "                t1.[release_year],\n",
    "                t2.[type], \n",
    "                t2.[rating], \n",
    "                t2.[duration],\n",
    "                t2.[listed_in],\n",
    "                t2.[description]\n",
    "            FROM smartsheet.dbo.test_movie_data_t1 t1\n",
    "            LEFT JOIN smartsheet.dbo.test_movie_data_t2 t2\n",
    "                ON t1.[show_id] = t2.[show_id];\n",
    "\n",
    "<img src=\"image/new_query.png\" alt=\"Create New Job\" width=\"300\" height=\"300\" style=\"margin-left: 10px; margin-bottom: 40px; margin-top: 20px;\" /> \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.7 Load SQL Data into Smartsheet & Test API Methods**  \n",
    "- Extract data from SQL Server and upload it to Smartsheet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your view/table into a dataframe\n",
    "source_df =  _sys_info_services.get_table_or_view_data('vw_test_movie_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the number of records for testing\n",
    "source_df_limited = source_df.iloc[0:10]\n",
    "\n",
    "# Load your source data into Smartsheet\n",
    "smartsheet_init.refresh_source_data(source_df_limited, sheet_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extra code - sample methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load smartsheet data into a dataframe\n",
    "sm_to_df = smartsheet_init.extract_and_load_to_dataframe_with_row_id(sheet_id)\n",
    "\n",
    "sm_to_df_no_row_id = sm_to_df.drop(columns=['row_id']) # removes a row id from the result set\n",
    "\n",
    "sm_to_df_no_row_id.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new data to the top of the Smartsheet without deleting all the data in the sheet prior to loading\n",
    "source_df_new_records = source_df.iloc[10:20]\n",
    "\n",
    "smartsheet_init.add_records_to_top_of_smartsheet(source_df_new_records, sheet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all data in the Smartsheet\n",
    "smartsheet_init.delete_sheet_data(sheet_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **2.8 Copy ODS Tables to Your Database**  \n",
    "- Perform data transfer from the ODS system to your target database.\n",
    "\n",
    "    -- Copy a table from one db to another using the statements below and replacing text as needed\n",
    "    - Select * into smartsheet.dbo.testDemo from [ODS_CLOUD]..[ONCORE].[ONCORE_ODS];\n",
    "    - Select * into smartsheet.dbo.testDemo2 from [ODS_CLOUD]..[ONCORE].[ONCORE_ODS];\n",
    "    \n",
    "<img src=\"image/new_query.png\" alt=\"Create New Job\" width=\"300\" height=\"300\" style=\"margin-left: 10px; margin-bottom: 40px; margin-top: 20px;\" />\n",
    "\n",
    "### **2.9 Create a Stored Procedure to Refresh ODS Data**  \n",
    "- Automate data updates using SQL stored procedures.\n",
    "\n",
    "<img src=\"image/stored_proc_location.png\" alt=\"Create New Job\" width=\"300\" height=\"300\" style=\"margin-left: 10px; margin-bottom: 40px; margin-top: 10px;\" />\n",
    "\n",
    "    -- Use CREATE for inital build and ALTER when updating\n",
    "    CREATE PROCEDURE SP_REFRESH_ODS_DATA\n",
    "    --ALTER PROCEDURE SP_REFRESH_ODS_DATA\n",
    "    AS\n",
    "    BEGIN\n",
    "        SET NOCOUNT ON;\n",
    "\n",
    "        -- Truncate table testDemo\n",
    "        TRUNCATE TABLE smartsheet.dbo.testDemo;\n",
    "\n",
    "        -- Insert data into testDemo\n",
    "        INSERT INTO smartsheet.dbo.testDemo (\n",
    "            [PROTOCOL_NO], \n",
    "            [IRB_NO], \n",
    "            [PI], \n",
    "            [CLINICAL_TRIAL], \n",
    "            [ORGANIZATION_UNIT], \n",
    "            [DEPARTMENT_NAME], \n",
    "            [MGMT_GROUP_DESCRIPTION], \n",
    "            [CURRENT_STATUS], \n",
    "            [OPEN_TO_ACCRUAL_DATE], \n",
    "            [TOTAL_ENROLLMENT], \n",
    "            [TARGET_ACCRUAL_UPPER], \n",
    "            [STUDY_SITE_CONTACT], \n",
    "            [SPONSOR_NAME], \n",
    "            [SPONSOR_TYPE_DESCRIPTION], \n",
    "            [FUND_ACCOUNTNO], \n",
    "            [GRANT_ACCOUNT], \n",
    "            [CLINICAL_TRIAL_FINANCE_STAFF], \n",
    "            [PI_V_NUMBER]\n",
    "        )\n",
    "        SELECT \n",
    "            [PROTOCOL_NO], \n",
    "            [IRB_NO], \n",
    "            [PI], \n",
    "            [CLINICAL_TRIAL], \n",
    "            [ORGANIZATION_UNIT], \n",
    "            [DEPARTMENT_NAME], \n",
    "            [MGMT_GROUP_DESCRIPTION], \n",
    "            [CURRENT_STATUS], \n",
    "            [OPEN_TO_ACCRUAL_DATE], \n",
    "            [TOTAL_ENROLLMENT], \n",
    "            [TARGET_ACCRUAL_UPPER], \n",
    "            [STUDY_SITE_CONTACT], \n",
    "            [SPONSOR_NAME], \n",
    "            [SPONSOR_TYPE_DESCRIPTION], \n",
    "            [FUND_ACCOUNTNO], \n",
    "            [GRANT_ACCOUNT], \n",
    "            [CLINICAL_TRIAL_FINANCE_STAFF], \n",
    "            [PI_V_NUMBER]\n",
    "        FROM [ODS_CLOUD]..[ONCORE].[ONCORE_ODS];\n",
    "\n",
    "        -- Truncate table testDemo2\n",
    "        TRUNCATE TABLE smartsheet.dbo.testDemo2;\n",
    "\n",
    "        -- Insert data into testDemo2\n",
    "        INSERT INTO smartsheet.dbo.testDemo2 (\n",
    "            [PROTOCOL_NO], \n",
    "            [IRB_NO], \n",
    "            [PI], \n",
    "            [CLINICAL_TRIAL], \n",
    "            [ORGANIZATION_UNIT], \n",
    "            [DEPARTMENT_NAME], \n",
    "            [MGMT_GROUP_DESCRIPTION], \n",
    "            [CURRENT_STATUS], \n",
    "            [OPEN_TO_ACCRUAL_DATE], \n",
    "            [TOTAL_ENROLLMENT], \n",
    "            [TARGET_ACCRUAL_UPPER], \n",
    "            [STUDY_SITE_CONTACT], \n",
    "            [SPONSOR_NAME], \n",
    "            [SPONSOR_TYPE_DESCRIPTION], \n",
    "            [FUND_ACCOUNTNO], \n",
    "            [GRANT_ACCOUNT], \n",
    "            [CLINICAL_TRIAL_FINANCE_STAFF], \n",
    "            [PI_V_NUMBER]\n",
    "        )\n",
    "        SELECT \n",
    "            [PROTOCOL_NO], \n",
    "            [IRB_NO], \n",
    "            [PI], \n",
    "            [CLINICAL_TRIAL], \n",
    "            [ORGANIZATION_UNIT], \n",
    "            [DEPARTMENT_NAME], \n",
    "            [MGMT_GROUP_DESCRIPTION], \n",
    "            [CURRENT_STATUS], \n",
    "            [OPEN_TO_ACCRUAL_DATE], \n",
    "            [TOTAL_ENROLLMENT], \n",
    "            [TARGET_ACCRUAL_UPPER], \n",
    "            [STUDY_SITE_CONTACT], \n",
    "            [SPONSOR_NAME], \n",
    "            [SPONSOR_TYPE_DESCRIPTION], \n",
    "            [FUND_ACCOUNTNO], \n",
    "            [GRANT_ACCOUNT], \n",
    "            [CLINICAL_TRIAL_FINANCE_STAFF], \n",
    "            [PI_V_NUMBER]\n",
    "        FROM [ODS_CLOUD]..[ONCORE].[ONCORE_ODS];\n",
    "        END;\n",
    "\n",
    "\n",
    "\n",
    "### **2.10 Schedule an Automated Data Refresh**  \n",
    "- Configure a SQL Agent Job to refresh ODS data on a schedule.  \n",
    "\n",
    "    - 2.10.01 Create new job  \n",
    "\n",
    "      <img src=\"image/schedule_new_job.png\" alt=\"Create New Job\" width=\"300\" height=\"300\" style=\"margin-left: 10px; margin-bottom: 40px; margin-top: 20px;\" />\n",
    "\n",
    "    - 2.10.02 Name new job and provide a description along with making sure you're the owner  \n",
    "\n",
    "      <img src=\"image/name_job.png\" alt=\"Name New Job\" width=\"700\" height=\"400\" style=\"margin-left: 10px; margin-bottom: 40px; margin-top: 20px;\" />\n",
    "\n",
    "    - 2.10.03 Create a new \"Step\" with a clear title and update the statement below with your stored proc and add this to the \"Command\" section  \n",
    "\n",
    "      <img src=\"image/create_new_step.png\" alt=\"Name New Job\" width=\"500\" height=\"500\" style=\"margin-left: 10px; margin-bottom: 40px; margin-top: 20px;\" />\n",
    "      <img src=\"image/new_step_name.png\" alt=\"Name New Job\" width=\"700\" height=\"500\" style=\"margin-left: 10px; margin-bottom: 40px; margin-top: 20px;\" />\n",
    "\n",
    "    - 2.10.04 Go to the \"Advanced\" tab and using the \"On success action\" select \"Quit the job reporting success\" and select OK  \n",
    "\n",
    "      <img src=\"image/quit_the_job.png\" alt=\"Name New Job\" width=\"900\" height=\"600\" style=\"margin-left: 10px; margin-bottom: 40px; margin-top: 20px;\" />\n",
    "\n",
    "    - 2.10.05 Use the \"Schedules\" tab to schedule as needed  \n",
    "\n",
    "      <img src=\"image/schedule_job_frequency.png\" alt=\"Name New Job\" width=\"700\" height=\"400\" style=\"margin-left: 10px; margin-bottom: 40px; margin-top: 20px;\" />\n",
    "\n",
    "    - 2.10.06 Use the \"Notifications\" tab to email when a job fails  \n",
    "\n",
    "      <img src=\"image/job_notifications.png\" alt=\"Name New Job\" width=\"800\" height=\"500\" style=\"margin-left: 10px; margin-bottom: 40px; margin-top: 20px;\" />\n",
    "\n",
    "    - 2.10.07 Select OK when done  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.11 Create an Optional View from ODS Data Tables**  \n",
    "- Build a SQL view to facilitate easier data access and analysis.\n",
    "   \n",
    "        -- Use CREATE for inital build and ALTER when updating\n",
    "        --  ALTER VIEW vw_testDemo AS\n",
    "            CREATE VIEW vw_testDemo AS\n",
    "            SELECT \n",
    "                t1.[PROTOCOL_NO], \n",
    "                t1.[IRB_NO], \n",
    "                t1.[PI], \n",
    "                t1.[CLINICAL_TRIAL], \n",
    "                t2.[ORGANIZATION_UNIT], \n",
    "                t2.[DEPARTMENT_NAME], \n",
    "                t2.[MGMT_GROUP_DESCRIPTION], \n",
    "                t2.[CURRENT_STATUS]\n",
    "            FROM smartsheet.dbo.testDemo t1\n",
    "            LEFT JOIN smartsheet.dbo.testDemo2 t2\n",
    "                ON t1.[IRB_NO] = t2.[IRB_NO];\n",
    "\n",
    "<img src=\"image/new_query.png\" alt=\"Create New Job\" width=\"300\" height=\"300\" style=\"margin-left: 10px; margin-bottom: 40px; margin-top: 20px;\" /> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.12 Review & Validate Data**  \n",
    "- Ensure data is correctly migrated and matches expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3: Tips & Tricks** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 Can We Load Data Directly from the ODS Linked Server?**  \n",
    "- ✅ Yes, but it depends on access permissions and performance considerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch from the linked server\n",
    "# Case 1: When the Linked Server Does Not Require a Database Name\n",
    "linked_df = _sys_info_services.get_table_or_view_data_from_linked_sql_server(\n",
    "    linked_server=\"ODS_CLOUD\",\n",
    "    linked_db=None,  # ✅ Uses \"..\" format\n",
    "    schema=\"VCU_CUSTOM\", \n",
    "    table_name=\"VCU_SUMMARY_RESIDENCY\"\n",
    ")\n",
    "\n",
    "\n",
    "linked_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch from the linked server\n",
    "# Case 2: When the Linked Server Requires a Database Name\n",
    "linked_df = _sys_info_services.get_table_or_view_data_from_linked_sql_server(\n",
    "    linked_server=\"ODS_CLOUD\",\n",
    "    linked_db=\"VCU_CUSTOM\",  # ✅ Database is required\n",
    "    schema=\"dbo\", \n",
    "    table_name=\"VCU_SUMMARY_RESIDENCY\"\n",
    ")\n",
    "\n",
    "linked_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 Other API Data Considerations**  \n",
    "- Handling different data structures via API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://open-meteo.com/en/docs\n",
    "url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "params = {\n",
    "\t\"latitude\": 52.52,\n",
    "\t\"longitude\": 13.41,\n",
    "\t\"hourly\": \"temperature_2m\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, params)\n",
    "response.json()['hourly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.DataFrame(response.json()['hourly'])\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.3 Can Python Jobs be Automated/Scheduled?**  \n",
    "- ✅ Yes, but it depends machine access and error checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "\n",
    "\n",
    "print('scheduler started')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create function to process via the schedule\n",
    "def sql_to_smartsheet_etl():\n",
    "    '''\n",
    "    funcation to move the data from SQL to smartsheet\n",
    "    '''\n",
    "    source_df =  _sys_info_services.get_table_or_view_data('vw_test_movie_demo')\n",
    "\n",
    "    # Limit the number of records for testing\n",
    "    source_df_limited = source_df.iloc[0:10]\n",
    "\n",
    "    # Load your source data into Smartsheet\n",
    "    smartsheet_init.refresh_source_data(source_df_limited, sheet_id)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run jobs in sepearte threads to avoid race conditions or other timing issues that would affect jobs starting\n",
    "def run_threaded(job_func):\n",
    "    job_thread = threading.Thread(target=job_func)\n",
    "    job_thread.start()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# build the jira_etl scheduler\n",
    "def smartsheet_etl_scheduler():\n",
    "    '''\n",
    "    scope:\n",
    "    funtion that helps schedule the extraction of data from SQL to land in smartsheet\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    # this is the listing of M-F as provided via datetime\n",
    "    weekdays = [0, 1, 2, 3, 4]\n",
    "\n",
    "    # get today at as int to check the list above to see if today is a weekday\n",
    "    today_as_int = dt.now().weekday()\n",
    "\n",
    "    ####### the following logic is used to determine if updates should occur and then processes accordingly\n",
    "\n",
    "    # The following logic checks conditions to determine if the following funtion should run\n",
    "    if today_as_int in weekdays:\n",
    "        print('start data extraction')\n",
    "        # funtion to extract data from polygon\n",
    "        sql_to_smartsheet_etl()\n",
    "\n",
    "        print('etl finished')\n",
    "\n",
    "    # if not a weekday:\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "smartsheet_etl_scheduled = schedule.Scheduler()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# schedule the jobs for 3am each M-F\n",
    "smartsheet_etl_scheduled.every().day.at('03:00').do(run_threaded, smartsheet_etl_scheduler) # make sure your refresh schedule is sync with the SQL refresh to allow lag time \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# loop the jobs forever until the process fails or system restarts \n",
    "while True:\n",
    "\n",
    "    smartsheet_etl_scheduled.run_pending()\n",
    "\n",
    "\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
